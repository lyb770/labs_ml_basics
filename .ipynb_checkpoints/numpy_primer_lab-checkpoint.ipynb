{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy Basics\n",
    "Numpy is the main package for scientific computing in Python. It is maintained by a large community (www.numpy.org).\n",
    "\n",
    "__Run the next cell to get access to numpy__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # this means you can access numpy functions by writing np.function() instead of numpy.function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why numpy\n",
    "Why do we need numpy? Let's compare computation time for python and numpy\n",
    "* Two vectors with $10^6$ elements each\n",
    " * first - from 0 to 1 000 000\n",
    " * second - from 99 to 1 000 099\n",
    " \n",
    "* Computing:\n",
    " * Sum of two vectors\n",
    " * Hadamard product – entrywise product of 2 vectors\n",
    " * Square root for each element of first array\n",
    " * Sum of all elements in the first array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option I: pure python\n",
      "CPU times: user 2.3 s, sys: 55.5 ms, total: 2.36 s\n",
      "Wall time: 2.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ^-- this \"magic\" measures and prints cell computation time\n",
    "\n",
    "print(\"Option I: pure python\")\n",
    "arr_1 = range(1000000)\n",
    "arr_2 = range(99, 1000099)\n",
    "\n",
    "\n",
    "a_sum = [0.0]*len(arr_1) \n",
    "a_prod = [0.0]*len(arr_1) \n",
    "sqrt_a1 = [0.0]*len(arr_1) \n",
    "for i in range(len(arr_1)):\n",
    "    a_sum[i] = arr_1[i]+arr_2[i]\n",
    "    a_prod[i] = arr_1[i]*arr_2[i]\n",
    "    a_sum[i] = arr_1[i]**0.5\n",
    "\n",
    "arr_1_sum = sum(arr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option II: start from python, convert to numpy\n",
      "CPU times: user 1.06 s, sys: 160 ms, total: 1.22 s\n",
      "Wall time: 1.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Option II: start from python, convert to numpy\")\n",
    "arr_1 = range(1000000)\n",
    "arr_2 = range(99, 1000099)\n",
    "\n",
    "arr_1, arr_2 = np.array(arr_1), np.array(arr_2)\n",
    "\n",
    "\n",
    "a_sum = arr_1 + arr_2\n",
    "a_prod = arr_1 * arr_2\n",
    "sqrt_a1 = arr_1 ** .5\n",
    "arr_1_sum = arr_1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option III: pure numpy\n",
      "CPU times: user 51.1 ms, sys: 0 ns, total: 51.1 ms\n",
      "Wall time: 54.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Option III: pure numpy\")\n",
    "arr_1 = np.arange(1000000)\n",
    "arr_2 = np.arange(99, 1000099)\n",
    "\n",
    "a_sum = arr_1 + arr_2\n",
    "a_prod = arr_1 * arr_2\n",
    "sqrt_a1 = arr_1 ** .5\n",
    "arr_1_sum = arr_1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can it be that numpy is almost as fast as C? Take a look at [this](https://notes-on-cython.readthedocs.io/en/latest/std_dev.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reshaping arrays ##\n",
    "\n",
    "Two important numpy functions are [np.shape()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html) and [np.reshape()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html). \n",
    "- X.shape is used to get the shape (dimension) of a matrix/vector X. \n",
    "- X.reshape(...) is used to reshape X into some other dimension. \n",
    "\n",
    "For example, an image can be represented by a 3D array of shape $(length, height, depth = 3)$. However, when you use an image as the input of an algorithm you often need to convert it to a vector of shape $(length*height*3, 1)$. In other words, you \"unroll\", or reshape, the 3D array into a 1D vector.\n",
    "\n",
    "<img src=\"images/image2vector_kiank.png\" style=\"width:500px;height:300;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:yellow;\">\n",
    "    <h3>Task 1</h3>\n",
    "    Implement <code>image2vector()</code> that takes an input of shape (length, height, 3) and returns a vector of shape (length*height*3, 1). For example, if you would like to reshape an array v of shape (a, b, c) into a vector of shape (a*b,c) you would do:\n",
    "<code>\n",
    "v = v.reshape((v.shape[0]*v.shape[1], v.shape[2])) \n",
    "# v.shape[0] = a \n",
    "# v.shape[1] = b \n",
    "# v.shape[2] = c\n",
    "</code>\n",
    "    <em>Note:</em> Please don't hardcode the dimensions of image as a constant. Instead look up the quantities you need with <code>image.shape[0]</code>, etc. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: image2vector\n",
    "def image2vector(image):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    image -- a numpy array of shape (length, height, depth)\n",
    "    \n",
    "    Returns:\n",
    "    v -- a vector of shape (length*height*depth, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    v = image.reshape((image.shape[0]*image.shape[1]* image.shape[2]), 1)\n",
    "   \n",
    "\n",
    "\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image2vector(image) = [[0.67826139]\n",
      " [0.29380381]\n",
      " [0.90714982]\n",
      " [0.52835647]\n",
      " [0.4215251 ]\n",
      " [0.45017551]\n",
      " [0.92814219]\n",
      " [0.96677647]\n",
      " [0.85304703]\n",
      " [0.52351845]\n",
      " [0.19981397]\n",
      " [0.27417313]\n",
      " [0.60659855]\n",
      " [0.00533165]\n",
      " [0.10820313]\n",
      " [0.49978937]\n",
      " [0.34144279]\n",
      " [0.94630077]]\n"
     ]
    }
   ],
   "source": [
    "# Test yourself.\n",
    "# This is a 3 by 3 by 2 array, typically images will be (num_px_x, num_px_y, 3) where 3 represents the RGB values\n",
    "image = np.array([[[ 0.67826139,  0.29380381],\n",
    "        [ 0.90714982,  0.52835647],\n",
    "        [ 0.4215251 ,  0.45017551]],\n",
    "\n",
    "       [[ 0.92814219,  0.96677647],\n",
    "        [ 0.85304703,  0.52351845],\n",
    "        [ 0.19981397,  0.27417313]],\n",
    "\n",
    "       [[ 0.60659855,  0.00533165],\n",
    "        [ 0.10820313,  0.49978937],\n",
    "        [ 0.34144279,  0.94630077]]])\n",
    "\n",
    "print (\"image2vector(image) = \" + str(image2vector(image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "     <tr> \n",
    "       <td> **image2vector(image)** </td> \n",
    "       <td> [[ 0.67826139]\n",
    " [ 0.29380381]\n",
    " [ 0.90714982]\n",
    " [ 0.52835647]\n",
    " [ 0.4215251 ]\n",
    " [ 0.45017551]\n",
    " [ 0.92814219]\n",
    " [ 0.96677647]\n",
    " [ 0.85304703]\n",
    " [ 0.52351845]\n",
    " [ 0.19981397]\n",
    " [ 0.27417313]\n",
    " [ 0.60659855]\n",
    " [ 0.00533165]\n",
    " [ 0.10820313]\n",
    " [ 0.49978937]\n",
    " [ 0.34144279]\n",
    " [ 0.94630077]]</td> \n",
    "     </tr>\n",
    "    \n",
    "   \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing basic functions with numpy ##\n",
    "\n",
    "### 3.1. Sigmoid function\n",
    "\n",
    "$sigmoid(x) = \\frac{1}{1+e^{-x}}$ is sometimes also known as the logistic function. It is a non-linear function used in Logistic Regression and in Simple Neural Networks.\n",
    "\n",
    "<img src=\"images/sigmoid.png\" style=\"width:500px;height:228px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:yellow;\">\n",
    "    <h3>Task 2</h3>\n",
    "    Implement a function that returns the sigmoid of a real number x. Use math.exp to implement the exponent.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: basic_sigmoid\n",
    "\n",
    "import math\n",
    "\n",
    "def basic_sigmoid(x):\n",
    "    \"\"\"\n",
    "    Compute sigmoid of x.\n",
    "\n",
    "    Arguments:\n",
    "    x -- A scalar\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    s = 1/(1 + math.exp(-x))\n",
    "   \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9525741268224334"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_sigmoid(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style = \"width:40%\">\n",
    "    <tr>\n",
    "    <td>** basic_sigmoid(3) **</td> \n",
    "        <td>0.9525741268224334 </td> \n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We rarely use the \"math\" library in Machine Learning because the inputs of the functions are mostly matrices and vectors. This is why numpy is more useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary -: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-96f8caa855c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### One reason why we use \"numpy\" instead of \"math\" in Machine Learning ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbasic_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# you will see this gives an error when you run it, because x is a vector.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-e61acc4dd943>\u001b[0m in \u001b[0;36mbasic_sigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m### START CODE HERE ### (≈ 1 line of code)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary -: 'list'"
     ]
    }
   ],
   "source": [
    "### One reason why we use \"numpy\" instead of \"math\" in Machine Learning ###\n",
    "x = [1, 2, 3]\n",
    "basic_sigmoid(x) # you will see this gives an error when you run it, because x is a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, if $ x = (x_1, x_2, ..., x_n)$ is a row vector then $np.exp(x)$ will apply the exponential function to every element of x. The output will thus be: $np.exp(x) = (e^{x_1}, e^{x_2}, ..., e^{x_n})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.71828183  7.3890561  20.08553692]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# example of np.exp\n",
    "x = np.array([1, 2, 3])\n",
    "print(np.exp(x)) # result is (exp(1), exp(2), exp(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hint:__ Any time you need more info on a numpy function, you can look at [the official documentation](https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.exp.html). \n",
    "\n",
    "You can also create a new cell in the notebook and write `np.exp?` (for example) to get quick access to the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to implement a new sigmoid function which can work on either a real number, a vector, or a matrix. The numpy array data structure can be used to represent all these shapes (vectors, matrices...).\n",
    "\n",
    "The sigmoid(x) is now defined as following:\n",
    "$$ \\text{For } x \\in \\mathbb{R}^n \\text{,     } sigmoid(x) = sigmoid\\begin{pmatrix}\n",
    "    x_1  \\\\\n",
    "    x_2  \\\\\n",
    "    ...  \\\\\n",
    "    x_n  \\\\\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "    \\frac{1}{1+e^{-x_1}}  \\\\\n",
    "    \\frac{1}{1+e^{-x_2}}  \\\\\n",
    "    ...  \\\\\n",
    "    \\frac{1}{1+e^{-x_n}}  \\\\\n",
    "\\end{pmatrix}\\tag{1} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:yellow;\">\n",
    "    <h3>Task 3</h3>\n",
    "    Implement the sigmoid function using numpy. \n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: sigmoid\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of x\n",
    "\n",
    "    Arguments:\n",
    "    x -- A scalar or numpy array of any shape\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    s = 1/(1+np.exp(-x))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73105858, 0.88079708, 0.95257413])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table>\n",
    "    <tr> \n",
    "        <td> **sigmoid([1,2,3])**</td> \n",
    "        <td> array([ 0.73105858,  0.88079708,  0.95257413]) </td> \n",
    "    </tr>\n",
    "</table> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Sigmoid gradient (derivative)\n",
    "\n",
    "We often need to compute derivatives of a given function (gradient) to optimize loss functions in many ML algorithms. Let's code your first gradient function.\n",
    "\n",
    "The gradient of the sigmoid function with respect to its input x is given by the formula: $$sigmoid\\_derivative(x) = \\sigma'(x) = \\sigma(x) (1 - \\sigma(x))\\tag{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:yellow;\">\n",
    "    <h3>Task 4</h3>\n",
    "    Implement the function <code>sigmoid_derivative(x)</code> to compute the gradient (also called the slope or derivative) of the sigmoid function with respect to its input x.\n",
    "</div> \n",
    "\n",
    "Hint: You can code this function in two steps:\n",
    "1. Set s to be the sigmoid of x. You might find your `sigmoid(x)` function useful.\n",
    "2. Compute $\\sigma'(x) = s(1-s)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: sigmoid_derivative\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    \"\"\"    \n",
    "    Arguments:\n",
    "    x -- A scalar or numpy array\n",
    "\n",
    "    Return:\n",
    "    ds -- Your computed gradient.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    y = sigmoid(x)\n",
    "    ds = y*(1-y)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid_derivative(x) = [0.19661193 0.10499359 0.04517666]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "print (\"sigmoid_derivative(x) = \" + str(sigmoid_derivative(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr> \n",
    "        <td> **sigmoid_derivative([1,2,3])**</td> \n",
    "        <td> [ 0.19661193  0.10499359  0.04517666] </td> \n",
    "    </tr>\n",
    "</table> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    <b>Summary</b>\n",
    "    <ul>\n",
    "        <li><code>numpy</code> works significantly faster than any other python library</li>\n",
    "        <li><code>numpy</code> has efficient built-in functions. For example, <code>np.exp(x)</code> works for any <code>np.array</code> <i>x</i> and applies the exponential function to every element of this array</li>       \n",
    "        <li><code>np.reshape</code> is widely used. For example <code>image2vector</code> is commonly used in deep learning for image classification.</li>\n",
    "    </ul>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This primer lab adopted from one of the assignments in coursera course ''Introduction to Machine Learning'' by Professor Andrew Ng. "
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XHpfv",
   "launcher_item_id": "Zh0CU"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
